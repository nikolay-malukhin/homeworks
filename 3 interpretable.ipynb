{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-model\" data-toc-modified-id=\"Creating-a-model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Creating a model</a></span></li><li><span><a href=\"#Feature-Importance\" data-toc-modified-id=\"Feature-Importance-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Importance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean-Decrease-Impurity\" data-toc-modified-id=\"Mean-Decrease-Impurity-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Mean Decrease Impurity</a></span></li><li><span><a href=\"#Permutation-Importance\" data-toc-modified-id=\"Permutation-Importance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Permutation Importance</a></span></li></ul></li><li><span><a href=\"#Feature-Contributions\" data-toc-modified-id=\"Feature-Contributions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Feature Contributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plotting-feature-contributions\" data-toc-modified-id=\"Plotting-feature-contributions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Plotting feature contributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Boxplots\" data-toc-modified-id=\"Boxplots-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Boxplots</a></span></li><li><span><a href=\"#Swarmplots\" data-toc-modified-id=\"Swarmplots-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Swarmplots</a></span></li><li><span><a href=\"#Plotting-Feature-Contributions-against-Feature-Values\" data-toc-modified-id=\"Plotting-Feature-Contributions-against-Feature-Values-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Plotting Feature Contributions against Feature Values</a></span></li><li><span><a href=\"#Heatmaps\" data-toc-modified-id=\"Heatmaps-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Heatmaps</a></span></li></ul></li></ul></li><li><span><a href=\"#Joint-Feature-Contributions\" data-toc-modified-id=\"Joint-Feature-Contributions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Joint Feature Contributions</a></span></li><li><span><a href=\"#PDP-and-ICE-plots\" data-toc-modified-id=\"PDP-and-ICE-plots-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>PDP and ICE plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Centered-ICE-Plots\" data-toc-modified-id=\"Centered-ICE-Plots-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Centered ICE Plots</a></span></li><li><span><a href=\"#Two-dimensional-PDPs\" data-toc-modified-id=\"Two-dimensional-PDPs-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Two-dimensional PDPs</a></span></li></ul></li><li><span><a href=\"#LIME\" data-toc-modified-id=\"LIME-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>LIME</a></span></li><li><span><a href=\"#SHAP\" data-toc-modified-id=\"SHAP-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>SHAP</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерпретация моделей машиннго обучения на Python\n",
    "\n",
    "\n",
    "В этой статье мы исследуем различные инструменты и методы, которые можно использовать для интерпретации моделей «черного ящика».\n",
    "\n",
    "Поскольку сегодня проходит <a href='https://ru.wikipedia.org/wiki/%D0%94%D1%80%D0%B0%D1%84%D1%82_%D0%9D%D0%A4%D0%9B'>драфт НФЛ</a>, я думаю, что было бы забавным использовать данные по <a href='https://en.wikipedia.org/wiki/NFL_Scouting_Combine'>НФЛ-комбинату</a>(ежегодных соревнований с целью выявить перспективных игроков). Используя эти данные, мы сначала построим модель для прогнозирования результатов начала карьеры играков защиты - <a href='https://ru.wikipedia.org/wiki/%D0%94%D0%B5%D1%84%D0%B5%D0%BD%D1%81%D0%B8%D0%B2_%D1%8D%D0%BD%D0%B4'>Дефенсив энд (англ. Defensive end, D-End) (DE)</a> . После этого мы будем использовать различные методы интерпретации для лучшего понимания модели.\n",
    "\n",
    "# Создание модели\n",
    "\n",
    "Давайте начнем с импорта того, что нам нужно для настройки данных и нашего конвейера моделирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skll.metrics import spearman\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# устанавлиаем настройки отображения графиков\n",
    "sns.set(style=\"white\", palette=\"colorblind\", font_scale=1.2, \n",
    "        rc={\"figure.figsize\":(12,9)})\n",
    "RANDOM_STATE = 420\n",
    "N_JOBS=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы загружаем данные, которые содержат общую информацию о всех игроках и их приблизительную стоимость (https://www.pro-football-reference.com/blog/index37a8.html) за 3 года, которую мы будем использовать в качестве показателя ранних результатов карьеры (и в дальнейшем мы будем сокращенно обозначать как <a href='https://www.pro-football-reference.com/blog/index37a8.html'>AV</a>).\n",
    "\n",
    "При построении нашей модели мы не будем предсказывать AV игроков защиты, вместо этого мы будем предсказывать его AV-ранг (в процентах) среди других защитников. Игроки с высоким AV должны быть ближе к 1, а игроки с низким AV - ближе к 0. \n",
    "\n",
    "**ПРИМЕЧАНИЕ:** Если вы хотите узнать, какие измеримые[combine measurables] [значения?имеют значение] для каждой позиции в НФЛ вы найдете ответы в [серии](http://harvardsportsanalysis.org/2015/02/the-nfl-combine-actually-matters/) посвященных этой теме [постов](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-3-predicting-the-draft/) [Била Лоттера](https://twitter.com/bill_lotter?lang=en) в его [блоге](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-2/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/combine_data_since_2000_PROCESSED_2018-04-26.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8556a0379c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# считываем данные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/combine_data_since_2000_PROCESSED_2018-04-26.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# выбираем игроков, которые состоят в лиге на протяжении трех лет или более\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYear\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# считаем AV[процент|перцентиль] игрока по его позиции [EN] calculate the player AV percentiles by position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/combine_data_since_2000_PROCESSED_2018-04-26.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# считываем данные\n",
    "data_df = pd.read_csv('data/combine_data_since_2000_PROCESSED_2018-04-26.csv')\n",
    "# выбираем игроков, которые состоят в лиге на протяжении трех лет или более\n",
    "data_df2 = data_df.loc[data_df.Year <= 2015].copy()\n",
    "# считаем AV[процент|перцентиль] игрока по его позиции [EN] calculate the player AV percentiles by position\n",
    "data_df2['AV_pctile'] = (data_df2.groupby('Pos')\n",
    "                                  .AV\n",
    "                                  .rank(pct=True,\n",
    "                                        method='min', \n",
    "                                        ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы загрузили данные и рассчитали [AV percentiles], приступим к отбору данных по защитникам (DE) и создадим обучающую и тестовую выборку. Мы обучим нашу модель на первых 8 годах (2000-2011) [?как-то не похоже на 8 лет?] и затем протестируем её на следующих четырех годах (2012-2015). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Отберем данные по интересующим нас позициям, в данно случае это защитники - DE\n",
    "pos_df = data_df2.loc[data_df2.Pos=='DE'].copy().reset_index(drop=True)\n",
    "\n",
    "# Разделим данные на обучающую и тестовую выборку\n",
    "train_df = pos_df.loc[pos_df.Year <= 2011]\n",
    "test_df = pos_df.loc[pos_df.Year.isin([2012, 2013, 2014, 2015])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be build a random forest model since that seems to be the [most common](https://www.kaggle.com/surveys/2017) \"black box\" algorithm people use at work. One thing to to note is that in our modeling `Pipeline` we will need to include an `Imputer` because some DEs are missing data as they did not participate in all the combine drills.\n",
    "\n",
    "Мы построим модель случайного леса, так как это [наиболее распространенный](https://www.kaggle.com/surveys/2017) алгоритм \"черного ящика\", который люди используют на практике. Следует отметить, что в наш `Pipeline` обработки данных мы должны будем включить `Imputer`, так как по части DE есть пропуски в данных, потому что они принимали участие не во всех соревнованиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измеренные параметры\n",
    "features = ['Forty',\n",
    "            'Wt',\n",
    "            'Ht',\n",
    "            'Vertical',\n",
    "            'BenchReps',\n",
    "            'BroadJump',\n",
    "            'Cone',\n",
    "            'Shuttle']\n",
    "# хто мы хотим предсказывать\n",
    "target = 'AV_pctile'\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[target].values\n",
    "\n",
    "# pipeline обработки данных\n",
    "pipe = Pipeline([(\"imputer\", Imputer()),\n",
    "                 (\"estimator\", RandomForestRegressor(random_state=RANDOM_STATE))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для настройки нашей модели мы будем использовать `BayesSearchCV` из `scikit-optimize`, который использует байесовскую оптимизацию для поиска наилучших гиперпараметров. Также мы будем использовать коэффициент корреляции Спирмена как нашу метрику оценки (scoring metric),  так как нас в основном интересует рейтинг игроков, когда речь идет о драфте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы используем коэффициент корреляции Спирмена как нашу метрику оценки\n",
    "# и нас интересует ранг спортсменов\n",
    "spearman_scorer = make_scorer(spearman)\n",
    "\n",
    "# поиск гиперпараметров для различных стратегий импутации данных\n",
    "rf_param_space = {\n",
    "    'imputer__strategy': Categorical(['mean', 'median', 'most_frequent']),\n",
    "    'estimator__max_features': Integer(1, 8),\n",
    "    'estimator__n_estimators': Integer(50, 500), \n",
    "    'estimator__min_samples_split': Integer(2, 200),\n",
    "}\n",
    "# создаем объект поиска\n",
    "search = BayesSearchCV(pipe, \n",
    "                      rf_param_space, \n",
    "                      cv=10,\n",
    "                      n_jobs=N_JOBS, \n",
    "                      verbose=0, \n",
    "                      error_score=-9999, \n",
    "                      scoring=spearman_scorer, \n",
    "                      random_state=RANDOM_STATE,\n",
    "                      return_train_score=True, \n",
    "                      n_iter=75)\n",
    "# обучение модели\n",
    "# я получил несколько странных предупреждений (funky warnings), возможно что из-за использования коэффициента корреляции Спирмена,\n",
    "# и я предпочет поавить их вывод\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    search.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лучшие параметры модели\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV score\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV стандартное отклонение\n",
    "search.cv_results_['std_test_score'][search.best_index_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы настроили нашу модель, давайте оценим ее на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестовый набор\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[target].values\n",
    "# предсказание\n",
    "y_pred = search.predict(X_test)\n",
    "# оценка\n",
    "model_test_score = spearman_scorer(search, X_test, y_test)\n",
    "model_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Таким образом, предсказания нашей модели имеют ранговую корреляцию Спирмена около 0,209. Хорошо это или плохо? Я не знаю. Чтобы лучше понять, насколько хороший или плохой результат, мы можем использовать фактические <a href='https://ru.wikipedia.org/wiki/%D0%94%D1%80%D0%B0%D1%84%D1%82_(%D1%81%D0%BF%D0%BE%D1%80%D1%82)'>пики драфта</a> в качестве способа сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем percentiles для пики драфта НФЛ\n",
    "# Меньшее численное значение пики (e.g. 1, 2, 3) ранжированно ближе к 1\n",
    "# Большее численное значение пики (e.g. 180, 200, etc) ранжированно ближе к 0\n",
    "draft_pick_pctile = test_df.Pick.rank(pct=True,\n",
    "                                      method='min', \n",
    "                                      ascending=False, \n",
    "                                      na_option='top')\n",
    "spearman(y_test, draft_pick_pctile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, что команды НФЛ в 3 раза лучше ранжируют DEs чем наша модель.\n",
    "\n",
    "Теперь, когда у нас есть модель, давайте рассмотрим различные инструменты для её лучшего понимания.\n",
    "\n",
    "# Значимость признаков\n",
    "\n",
    "## Mean Decrease Impurity  ( усредненное уменьшение Джини ?)\n",
    "\n",
    "Если вы испальзуете ансамбль деревьев решений, например случайный лес, вы можете оценить то, какие параметры модель считает более значимыми проверяя значимость признаков.  В `scikit-learn` значимость признаков отражает то, как признак уменьшает некий критерий. В нашей регрессионной моели этот критерий - средняя квадратичная ошибка.  Этот метод рассчета значимости признака обычно называется mean decrease impurity или gini importance.\n",
    "\n",
    "Мы можем получить доступ к значимостям признаков нашей модели при помощи `feature_importances_` аттрибута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# берем estimator и imputer из нашего pipeline, \n",
    "# который будет использоваться, когда мы пытаемся интерпретировать нашу модель\n",
    "estimator = search.best_estimator_.named_steps['estimator']\n",
    "imputer = search.best_estimator_.named_steps['imputer']\n",
    "\n",
    "estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве альтернативы, мы можем использовать `explain_weights_df` функцию  из пакета`eli5`, которая возвращает значимости и имена признаков, которые мы передадим в неё как `DataFrame` в `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "# создаем датафрейм значимости признаков\n",
    "feat_imp_df = eli5.explain_weights_df(estimator, feature_names=features)\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже на то, что вес игрока и его результат в беге на 40 ярдов(<a href='https://ru.wikipedia.org/wiki/%D0%91%D0%B5%D0%B3_%D0%BD%D0%B0_40_%D1%8F%D1%80%D0%B4%D0%BE%D0%B2'>forty time</a>) являются значимыми признаками для модели. Нужно отметить, что `explain_weights_df` также возвращает стандартные отклонения, но они могут быть ненадежными, поскольку эти значения предполагают нормальное распределение. Вместо того, чтобы полагаться на эти стандартные отклонения, мы можем получить доступ к каждому дереву в нашем ансамбле и построить полное распределение значений функций.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем значимость признаков для каждого дерева и затем визуализируем их распределения как boxplots\n",
    "all_feat_imp_df = pd.DataFrame(data=[tree.feature_importances_ for tree in \n",
    "                                     estimator],\n",
    "                               columns=features)\n",
    "\n",
    "(sns.boxplot(data=all_feat_imp_df)\n",
    "        .set(title='Распределения значимости признаков',\n",
    "             ylabel='Значимость'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пермутированная  важность(?англ. Permutation Importance)\n",
    "\n",
    "Важность перестановок(?англ. Permutation Importance) или среднее снижение точности(?англ. mean decrease accuracy (MDA)) это альтернатива примеси (критерий) Джини(?англ. mean decrease impurity) метрика, которая может быть использована в любой модели. Главная идея важности перестановок (?англ. permutation importance) это перестановка значений каждого предиктора и оценка того, насколько сильно эта перестановка негативно влияет на метрику скоринга (в нашем случае это клэфициент корреляции ранга Спирмена).  Это дает нам представление о том, как наша модель бует работать беэ этого конкретного признака. Все что нам нужно, это рассчитать важность перестановок используя `PermutationImportance` из `eli5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# нам нужно импутировать анные преже, чем рассчитывать permutation importance\n",
    "train_X_imp = imputer.transform(X)\n",
    "# настраиваем met-estimator(?метапараметр?) для рассчета permutation importance на нашей учебной выборке данных\n",
    "perm_train = PermutationImportance(estimator, scoring=spearman_scorer,\n",
    "                                   n_iter=50, random_state=RANDOM_STATE)\n",
    "# обучаем и смотрим permuation importances\n",
    "perm_train.fit(train_X_imp, y)\n",
    "eli5.explain_weights_df(perm_train, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# построим график распреелений\n",
    "perm_train_feat_imp_df = pd.DataFrame(data=perm_train.results_,\n",
    "                                      columns=features)\n",
    "(sns.boxplot(data=perm_train_feat_imp_df)\n",
    "        .set(title='Permutation Importance Распрееление (учебная выборка)',\n",
    "             ylabel='Значимость'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основываясь на permutation importances мы снова видим что вес(Wt) и бег на 40 ярдов(Forty) это ва наших главных предиктора модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вклады признаков (англ. Feature Contributions)\n",
    "\n",
    "Метрика значимости предикторов может подсказать нам идеи о том, какие параметры модели наиболее значимы, но она ничего не скажет нам о том, как эти параметры влияют на предсказания нашей модели. Единственный способ сделать это - использовать пути в наших деревьях чтобы увидеть насколько сильно каждый параметр меняет предсказание когда мы движемся от родительского узла к дочернему узлу.\n",
    "В конце концов, мы можем разбить эти вклады параметров линейным образом, чтобы наши прогнозы можно было интерпретировать следующим образом: \n",
    "\n",
    "$$prediction = bias + feature_{1}contribution + feature_{2}contribution +... feature_{n}contribution$$\n",
    "\n",
    "\n",
    "Андо Саабас написал [несколько](http://blog.datadive.net/interpreting-random-forests/) [статей](http://blog.datadive.net/random-forest-interpretation-conditional-feature-contributions/) [в блоге](http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/)  для более подробного разбора этой темы. Сейчас я попытаюсь объяснить, как рассчитываются вклады параметров, рассмотрев пример, в котором в нашем лесу используется дерево небольшой глубины(англ. shallow tree). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from io import StringIO  \n",
    "\n",
    "# код примеров взят из:\n",
    "# https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176\n",
    "# Берем все деревья глубиною 2 в случайном лесу\n",
    "depths2 = [tree for tree in estimator.estimators_ if tree.tree_.max_depth==2]\n",
    "# выбираем первое\n",
    "tree = depths2[0]\n",
    "# строим график дерева\n",
    "dot_data = StringIO()\n",
    "export_graphviz(tree, out_file=dot_data, feature_names=features, \n",
    "                filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы упростить задачу, давайте оценим вклады параметров для игрока, который следует по левому пути в дереве выше, допустим, игрок, который весит 260 фунтов и пробегает сорок ярдов за 4,6 секунды.\n",
    "\n",
    "Начинаем с корневого (верхнего) узла, где средний AV-процентиль всех сэмплов равен 0,414 (это значение нашего смещения). При первом разделении дерево учитывает, весит ли игрок 270,5 фунтов или меньше, поэтому любое изменение в прогнозе, вызванное этим разделением, связано с весом игрока. Наш игрок попадает в левый дочерний узел, потому что он весит 260 фунтов.\n",
    "\n",
    "Since the average percentile at this node is 0.317 versus 0.414 in the parent node, we can say that the player's weight caused a decrease of 0.097 percentage points in his predicted AV percentile.  Now for the split at this new node, the tree considers whether the player runs a 4.755 forty or less. The player in our example runs a 4.6 forty, so after this split, he ends up in the leftmost leaf node of the tree. \n",
    "\n",
    "Поскольку средний процентиль в этом узле равен 0,317 против 0,414 в родительском узле, мы можем сказать, что вес игрока вызвал уменьшение его прогнозируемого AV-процентиля на 0,097 процентных пункта. Теперь для разделения на этом новом узле дерево учитывает, пробежал ли игрок сорок ярдов за 4,755 сек. или меньше. Игрок в нашем примере пробежал за 4.6 сек., поэтому после этого разделения он оказывается в крайнем левом листе дерева.\n",
    "\n",
    "At this leaf node the player's final predicted percentile is 0.481, since that is an increase of 0.164 percentage points from the previous node, we can say that the player's forty time contributed 0.164 percentage points to his predicted AV percentile.\n",
    "In the end, the feature contributions for this player's predicted AV percentile are as follows:\n",
    "\n",
    "В этом листовом узле конечный прогнозируемый процентиль игрока равен 0,481, то есть он увеличился на 0,164 процентных пункта по сравнению с предыдущим узлом, и мы можем сказать, что результат игрока в беге на сорок ярдов добавил 0,164 процентных пункта в его прогнозируемый AV-процентиль.\n",
    "В итоге, вклад в функцию для прогнозируемого AV-процентиля этого игрока выглядит следующим образом:\n",
    "\n",
    "$$\\underset{\\text{AV %ile}}{0.481} = \\underset{\\text{bias}}{0.414}-\\underset{\\text{Wt}}{0.097}+\\underset{\\text{Forty}}{0.164}$$\n",
    "\n",
    "Давайте посмотрим, какие значения вклаов параметров мы получим с помощью функции `explain_prediction_df` из библиотеки `eli5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# простой пример игрока с результатом в беге 4.6 сек. и весом в 260 фунтов\n",
    "example = np.array([4.6, 260, 0, 0, 0, 0, 0, 0])\n",
    "eli5.explain_prediction_df(tree, example, feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы можем ожидать прогноза нашего дерева в 0.481."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.predict(example.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так и есть. Чтобы вычислить ? (aнгл. bias term) и вклады признаков для всего леса деревьев, все, что вам нужно сделать, это усреднить условия смещения(aнгл. bias terms) и вклады параметров для всех деревьев.\n",
    "\n",
    "**NOTE:** Я знаю две библиотеки, которые позволяют легко вычислять эти виды вкладов параметров, `eli5` и  `treeintepretter`. Они отличаются друг от друга как API, так и алгоритмами, которые они могут использовать. `treeinterpretter` на данный момент работает для следующих эстиматоров `scikit-learn`:\n",
    "\n",
    "- DecisionTreeRegressor\n",
    "- DecisionTreeClassifier\n",
    "- ExtraTreeRegressor\n",
    "- ExtraTreeClassifier\n",
    "- RandomForestRegressor\n",
    "- RandomForestClassifier\n",
    "- ExtraTreesRegressor\n",
    "- ExtraTreesClassifier\n",
    "\n",
    "`eli5` работает как для тех же, вдобавок также работает и для эстиматора градиентного бустинга в `scikit-learn` и  LightGBM-эстиматора.\n",
    "\n",
    "\n",
    "Теперь давайте получим вклады параметров для каждой выборки в наших учебном и тестовом наборах данных. Помните, `explain_prediction_df` считает вклады наблюдений по одному, и может занимать много времени. Чтобы ускорить процесс, я написал вспомогательную функцию, которая позволяет нам использовать несколько процессов (то есть несколько ядер ЦП)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def multiproc_iter_func(max_workers, an_iter, func, item_kwarg, **kwargs):\n",
    "    \"\"\"\n",
    "    Вспомогательная функция, которая многопоточно применяется к каждому элементу в итерируемой\n",
    "    последовательности.\n",
    "    'item_kwarg' это keyword аргумент элемента в итерируемой последовательности, которая передена в функцию\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_results = [executor.submit(func, **{item_kwarg: item}, **kwargs)\n",
    "                          for item in an_iter]\n",
    "\n",
    "        results = [future.result() for future in future_results]\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание учебного набора вкладов\n",
    "# создание списка всех атрибутов обучающего набора данных\n",
    "train_expl_list = multiproc_iter_func(N_JOBS, train_X_imp, \n",
    "                                      eli5.explain_prediction_df, 'doc',\n",
    "                                      estimator=estimator, \n",
    "                                      feature_names=features)\n",
    "# Конкатенируем их в 1 большой датафрейм, с правильным именем играка в качестве индекса\n",
    "train_expl_df = pd.concat(train_expl_list, keys=train_df.Player, \n",
    "                          names=['Player'])\n",
    "# Посмотрим на несколько первых игроков.\n",
    "train_expl_df.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание тестового набора вкладов\n",
    "# нам необходимо импутировать пропущенные значения в тестовом наборе\n",
    "test_X_imp = imputer.transform(X_test)\n",
    "# повторяем то, что мы сделали для обучающего набора данных\n",
    "test_expl_list = multiproc_iter_func(N_JOBS, test_X_imp, \n",
    "                                     eli5.explain_prediction_df, 'doc', \n",
    "                                     estimator=estimator,\n",
    "                                     feature_names=features)\n",
    "\n",
    "test_expl_df = pd.concat(test_expl_list, keys=test_df.Player, \n",
    "                         names=['Player'])\n",
    "test_expl_df.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Двойная проверка что суммы вкладов равны действительным предсказаниям\n",
    "y_pred_sums = test_expl_df.groupby('Player').weight.sum()\n",
    "np.allclose(y_pred, y_pred_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение графика вкладов признаков\n",
    "Теперь, когда у нас есть все вклады признаков, построим несколько графиков, чтобы лучше разобраться в них.\n",
    "\n",
    "### Ящики с усами(боксплот)\n",
    "Для начала построим ящик с усами, чтобы увидеть чтобы увидеть распределения вкладов каждого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим большой датасет, который будет включать и учебный, и проверочный набор дынных.\n",
    "# чтобы построить их график, используя боксплот от seaborn\n",
    "train_expl_df.rename(columns={'weight': 'contribution'}, inplace=True)\n",
    "test_expl_df.rename(columns={'weight': 'contribution'}, inplace=True)\n",
    "train_expl_df['data'] = 'train'\n",
    "test_expl_df['data'] = 'test'\n",
    "train_test_expl_df = pd.concat([train_expl_df, test_expl_df])\n",
    "sns.boxplot(x='feature', y='contribution', hue='data', order=features,\n",
    "            data=train_test_expl_df.loc[train_test_expl_df.feature!='<BIAS>'],\n",
    "            palette={'train': 'salmon', \n",
    "                     'test':'deepskyblue'})\n",
    "plt.legend(loc=9)\n",
    "plt.title('Распределение вкладов признаков');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swarmplots(?)\n",
    "\n",
    "мы также можем воспользоваться swarmplots, которые могут позволить нам более детально оцинить распределение, так как они строятся для каждого отдельного наблюдения.\n",
    "Если мы закрасим каждую точку масштабированным значением связанного признака, мы можем увидеть как изменяется значение признака вместе с его вкладом.\n",
    "\n",
    "\n",
    "<i>We can also use swarmplots which allow for a more granular view of the distribution since they plot each individual observation. If we color each point by the associated feature's (scaled) value, we can view how the change in a feature's value changes along with its contribution.</i>\n",
    "\n",
    "`seaborn` не поддерживает colorbar по умолчанию, так что нам нужно будет добавить его самостоятельно.\n",
    "Я сделал функию (основываясь на [этой](https://stackoverflow.com/questions/40814612/map-data-points-to-colormap-with-seaborn-swarmplot) stackoverflow answer) Которая дает нам возможность добавить вертикальный colorbar справа от нашего swarmplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colorbar import ColorbarBase\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательная функция, которая отображает Swarmplot вместе с цветовой шкалой\n",
    "# использован код, найденный здесь:\n",
    "# https://stackoverflow.com/questions/40814612/map-data-points-to-colormap-with-seaborn-swarmplot\n",
    "def swarmplot_with_cbar(cmap, cbar_label, *args, **kwargs):\n",
    "    fig = plt.gcf()\n",
    "    ax = sns.swarmplot(*args, **kwargs)\n",
    "    # удалим легенду, потому что мы хотим показать вместо неё цветную полосу\n",
    "    ax.legend().remove()\n",
    "    ## создаем цветовую шкалу ##\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax_cb = divider.new_horizontal(size=\"3%\", pad=0.05)\n",
    "    fig.add_axes(ax_cb)\n",
    "    cb = ColorbarBase(ax_cb, cmap=cmap, orientation='vertical')\n",
    "    cb.set_label(cbar_label, labelpad=10)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мин-макс масштабирование значений объекта позволяет нам использовать цвет\n",
    "# to indicate high or low feature values\n",
    "train_scaled_feat_vals = (train_expl_df.groupby('feature')\n",
    "                                       .value\n",
    "                                       .transform(lambda x: x/x.max()))\n",
    "\n",
    "train_expl_df['scaled_feat_vals'] = train_scaled_feat_vals\n",
    "\n",
    "cmap = plt.get_cmap('viridis')\n",
    "cbar_label = 'Значение признака %ile'\n",
    "\n",
    "plt.title('Распределение вкладов признаков (обучающая выборка)')\n",
    "swarmplot_with_cbar(cmap, cbar_label,  x='feature', y='contribution',\n",
    "                    hue='scaled_feat_vals', palette='viridis', order=features,\n",
    "                    data=train_expl_df.loc[train_expl_df.feature!='<BIAS>']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_scaled_feat_vals = (test_expl_df.groupby('feature')\n",
    "                                      .value\n",
    "                                      .transform(lambda x: x/x.max()))\n",
    "\n",
    "test_expl_df['scaled_feat_vals'] = test_scaled_feat_vals\n",
    "\n",
    "plt.title('Распределение вкладов признаков (тестовая выборка)')\n",
    "swarmplot_with_cbar(cmap, cbar_label,  x='feature', y='contribution',\n",
    "                    hue='scaled_feat_vals', palette='viridis', order=features,\n",
    "                    data=test_expl_df.loc[test_expl_df.feature!='<BIAS>']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on both plots, we can see that faster forty times and higher weights result in more positive contributions.  The other features tend to have most of their contributions hover around 0.  It's also interest to note the gaps in middle of the Wt distributions on both plots.\n",
    "\n",
    "### Plotting Feature Contributions against Feature Values\n",
    "\n",
    "Let's plot the feature contributions against the feature values to get a better sense of how they relate to one another.  We can use `seaborn`'s `lmplot` to easily create a grid of these kinds of plots for both our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.lmplot(x='value', y='contribution', col='feature',\n",
    "                data=train_expl_df.loc[train_expl_df.feature!='<BIAS>'], \n",
    "                col_order=features, sharex=False, col_wrap=3, fit_reg=False,\n",
    "                size=4, scatter_kws={'color':'salmon', 'alpha': 0.5, 's':30})\n",
    "fg.fig.suptitle('Feature Contributions vs Feature Values (training data)')\n",
    "fg.fig.subplots_adjust(top=0.90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fg = sns.lmplot(x='value', y='contribution', col='feature',\n",
    "                data=test_expl_df.loc[test_expl_df.feature!='<BIAS>'], \n",
    "                col_order=features, sharex=False, col_wrap=3, fit_reg=False, \n",
    "                size=4, scatter_kws={'color':'salmon', 'alpha': 0.5, 's':30})\n",
    "fg.fig.suptitle('Feature Contributions vs Feature Values (testing data)')\n",
    "fg.fig.subplots_adjust(top=0.90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both plots for Wt it's interesting to see the rapid increase in contribution at around 270 lbs.  The model essentially believes that weighing more than 270 is automatically a positive factor for a player, while weighing less than that is a negative one.\n",
    "\n",
    "One thing to note about these plots is that when we see different contributions (e.g. -0.05, -0.10, -0.15) for the same feature value (e.g. a forty time of 5 seconds) there is probably another feature (or set of features) that is causing these differences. To view such feature interactions we can set the color of the dots to reflect the value of another feature.  Let's take a look at how a player's weight interacts with the contribution of their forty time (at least in the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we actually plot anything we need to do a bit of data manipulation\n",
    "# let's pivot the data and create a new dataframe where the columns are\n",
    "# the feature contributions and each row is a player, with the player\n",
    "# name as the index value\n",
    "# here are different ways to pivot column values to columns\n",
    "# https://stackoverflow.com/questions/26255671/pandas-column-values-to-columns\n",
    "# based on running %%timeit, the groupby method was fastest \n",
    "train_contrib_df = (train_expl_df.groupby(['Player','feature'])\n",
    "                                 .contribution\n",
    "                                 .aggregate('first')\n",
    "                                 .unstack())\n",
    "# add in the feature values\n",
    "train_feat_contrib_df = train_contrib_df.merge(train_df[['Player'] + features],\n",
    "                                               how='left', left_index=True, \n",
    "                                               right_on='Player',\n",
    "                                               suffixes=('_contrib', '_value'))\n",
    "# now we can plot\n",
    "plt.scatter(x='Forty_value', y='Forty_contrib', c='Wt_value', cmap=cmap,\n",
    "            data=train_feat_contrib_df)\n",
    "plt.xlabel('Forty')\n",
    "plt.ylabel('contribution')\n",
    "plt.colorbar(label='Wt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some interaction between weight and forty time. Given a specific forty time, players with higher weights tend to have a more positive (or less negative) contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps\n",
    "With a little data wrangling and `seaborn`'s `heatmap` function we can take a look at the full set of contributions for each player in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_heatmap(data1, data2, cbar_label1, cbar_label2,\n",
    "                   title='', subplot_top=0.86, cmap1='viridis', cmap2='magma', \n",
    "                   center1=0.5, center2=0, grid_height_ratios=[1,4],\n",
    "                   figsize=(14,10)):\n",
    "    # do the actual plotting\n",
    "    # here we plot 2 seperate heatmaps one for the predictions and actual percentiles\n",
    "    # the other for the contributions\n",
    "    # the reason I chose to do this is because of the difference in magnitudes\n",
    "    # between the percentiles and the contributions\n",
    "    fig, (ax,ax2) = plt.subplots(nrows=2, figsize=figsize, \n",
    "                                 gridspec_kw={'height_ratios':grid_height_ratios})\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.subplots_adjust(hspace=0.02, top=subplot_top)\n",
    "\n",
    "    # heatmap for actual and predicted percentiles\n",
    "    sns.heatmap(data1, cmap=\"viridis\", ax=ax, xticklabels=False, center=center1,\n",
    "                cbar_kws={'location':'top', \n",
    "                          'use_gridspec':False, \n",
    "                          'pad':0.1,\n",
    "                          'label': cbar_label1})\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # heatmap of the feature contributions\n",
    "    sns.heatmap(data2, ax=ax2, xticklabels=False, center=center2, cmap=cmap2,\n",
    "                cbar_kws={'location':'bottom', \n",
    "                          'use_gridspec':False, \n",
    "                          'pad':0.07, \n",
    "                          'shrink':0.41,\n",
    "                          'label': cbar_label2})\n",
    "    ax2.set_ylabel('');\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction and actual target values to plot\n",
    "y_test_and_pred_df = pd.DataFrame(np.column_stack((y_test, y_pred)),\n",
    "                                  index=test_df.Player,\n",
    "                                  columns=['true_AV_pctile', 'pred_AV_pctile'])\n",
    "\n",
    "# let's pivot the data such that the feature contributions are the columns\n",
    "test_heatmap_df = (test_expl_df.groupby(['Player','feature'])\n",
    "                               .contribution\n",
    "                               .aggregate('first')\n",
    "                               .unstack())\n",
    "\n",
    "# there may be some NaNs if a feature did not contribute to a prediction, \n",
    "# so fill them in with 0s\n",
    "test_heatmap_df = test_heatmap_df.fillna(0)\n",
    "\n",
    "# merge our predictions with the the contributions\n",
    "test_heatmap_df = test_heatmap_df.merge(y_test_and_pred_df, how='left',\n",
    "                                        right_index=True, left_index=True)\n",
    "# sort by predictions\n",
    "test_heatmap_df.sort_values('pred_AV_pctile', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Feature contributions to predicted AV %ile \\nfor each player in the testing data'\n",
    "fig = double_heatmap(test_heatmap_df[['true_AV_pctile', 'pred_AV_pctile']].T,\n",
    "                     test_heatmap_df[features].T, '%ile', 'contribution',\n",
    "                     title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above consist of two heatmaps. Each column in both heatmaps represents a player. The rows in the top heatmap represent the true and predicted AV percentiles while the rows in the bottom heatmap represent the the feature contributions for each player prediction.\n",
    "\n",
    "I like the above visualization because it makes it easy to view a large set of predictions and contributions all at once. I definitely prefer it over the alternative of viewing each set of contributions through a printout out of the `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Feature Contributions\n",
    "\n",
    "A benefit of using a tree-ensemble like our random forest model, is that it captures interactions among our features without us explicitly defining them.  However in our attempt to interpret our model we have only looked at the importances and contributions of individual features.  Since we've yet to measure the impact of the feature interactions that the model has found, we have an incomplete picture of what our model is actually doing.  To gain some insight into these feature interactions we can use the `treeinterpeter` package. It uses the same method as before to calculate contributions, but instead of crediting individual features along the decision paths, `treeinterpeter` allows us to credit the feature interactions.\n",
    "\n",
    "**NOTE:** If you use XGBoost you can use the [xgbfir](https://github.com/limexp/xgbfir) package to inspect feature interactions. \n",
    "\n",
    "Let's use `treeinterpreter` on our simple decision tree from before, in order to get an idea of of how joint feature contributions (i.e. the contributions of the feature interactions) are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a reminder of what the tree looks like\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the joint feature contributions, we pass in our estimator and the data to the `predict` function and set `joint_contribution` to `True`.  That should return the prediction, the bias term and the joint feature contributions for our player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treeinterpreter.treeinterpreter as ti\n",
    "# get the contributions for our simple player example\n",
    "# who has a 4.6 forty and weighs 260 lbs\n",
    "# joint_contribution=True gets the joint feature contributions\n",
    "# when set to False it just returns the individual feature contributions\n",
    "example_pred, example_bias, example_contrib = ti.predict(tree,\n",
    "                                                         example.reshape(1, -1),\n",
    "                                                         joint_contribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same prediction as before\n",
    "example_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same bias value as before\n",
    "example_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint contributions are returned as list of dictionaries (in our example one dictionary for our one player), where the keys are numeric tuples representing the features (0 represents Forty and 1 represent Wt) and the values are the joint feature contributions. The joint feature contributions for our simple example are as follows:\n",
    "\n",
    "$$\\underset{\\text{AV %ile}}{0.481} = \\underset{\\text{bias}}{0.414}-\\underset{\\text{Wt}}{0.097}+\\underset{\\text{Forty & Wt}}{0.164}$$\n",
    "\n",
    "The contributions are the same values as before, the difference we see here is that instead of crediting the contribution of 0.164 percentage points to just the player's forty time, we also credit the previous feature, Wt, in the decision path. Remember, we are now crediting feature interactions, not just individual features. We only credit a single feature when it's either at the root node (like Wt is) or if it's the only feature used along a decision path.\n",
    "\n",
    "\n",
    "Let's get the joint feature contributions for the test set predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_pred, joint_bias, joint_contrib = ti.predict(estimator,\n",
    "                                                   test_X_imp,\n",
    "                                                   joint_contribution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check predictions are correct\n",
    "np.allclose(y_pred, joint_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bias is still the same\n",
    "joint_bias[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 96 observations in test set\n",
    "len(joint_contrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples representing the column indexes of our features\n",
    "list(joint_contrib[0].keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of a joint feature contribution\n",
    "joint_contrib[0][(0, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the joint feature contributions into more useable format let's match the tuples of indexes to the proper feature names. Then we can construct a `DataFrame` of each player's joint feature contributions, ordered by the absolute value of the contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordered_joint_contrib_df(contrib):\n",
    "    \"\"\"\n",
    "    Creates a dataframe from the joint contribution info, where the\n",
    "    feature combinations are ordered (in descending fashion) by the absolute\n",
    "    value of the joint contribution.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(contrib, columns=['feat_interaction', 'contribution'])\n",
    "    # get the reordered index    \n",
    "    new_idx = (df.contribution.abs()\n",
    "                              .sort_values(inplace=False, ascending=False)\n",
    "                              .index)\n",
    "    df = df.reindex(new_idx).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# add the names of the feats to the joint contributions\n",
    "joint_contrib_w_feat_names = []\n",
    "# for each observation in the join contributions\n",
    "for obs in joint_contrib:\n",
    "    # create a list\n",
    "    obs_contrib = []\n",
    "    # for each tuple of column indexes\n",
    "    for k in obs.keys():\n",
    "        # get the associated feature names\n",
    "        feature_combo = [features[i] for i in k]\n",
    "        # get the contribution value\n",
    "        contrib = obs[k]\n",
    "        # store that information in the observation individual list\n",
    "        obs_contrib.append([feature_combo, contrib])\n",
    "    # append that individual to the large list containing each observations\n",
    "    # joint feature contributions\n",
    "    joint_contrib_w_feat_names.append(obs_contrib)\n",
    "\n",
    "# create an ordered dataframe for each player\n",
    "joint_contrib_dfs = [create_ordered_joint_contrib_df(contrib)\n",
    "                     for contrib in joint_contrib_w_feat_names]\n",
    "# now combine them all\n",
    "joint_contrib_df = pd.concat(joint_contrib_dfs, keys=test_df.Player, names=['Player'])\n",
    "\n",
    "# edit feat_interaction column so the values are strings and not lists\n",
    "joint_contrib_df['feat_interaction'] = joint_contrib_df.feat_interaction.apply(' | '.join) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_contrib_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have the joint feature contributions for each player in our test set in a nice `DataFrame`.  Let's take a look at how important each feature and feature interaction is to our predictions. To do that we will measure (as a percentage) how much of the total joint contributions an individual feature or feature interaction is responsible for. In other words we are going to measure the relative importance of each feature and feature interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the sum of the absolute values for each joint feature contribution\n",
    "abs_imp_joint_contrib = (joint_contrib_df.groupby('feat_interaction')\n",
    "                                          .contribution\n",
    "                                          .apply(lambda x: x.abs().sum())\n",
    "                                           .sort_values(ascending=False))\n",
    "\n",
    "# then calculate the % of total contribution by dividing by the sum of all absolute vals\n",
    "rel_imp_join_contrib = abs_imp_joint_contrib / abs_imp_joint_contrib.sum()\n",
    "\n",
    "rel_imp_join_contrib.head(15)[::-1].plot(kind='barh', color='salmon', \n",
    "                                              title='Joint Feature Importances');\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('% of total joint contributions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the interaction between a Forty and Wt was the most important feature interaction in our predictions, accounting for over 20% of the joint feature contributions. Overall Forty, Wt and their interaction account for more than 50% of the total feature contributions.\n",
    "\n",
    "We can also take a look at the distributions of contributions for each feature and feature interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_feat_interactions = rel_imp_join_contrib.head(15).index\n",
    "top_contrib_mask = joint_contrib_df.feat_interaction.isin(top_feat_interactions)\n",
    "sns.boxplot(y='feat_interaction', x='contribution', \n",
    "            data=joint_contrib_df.loc[top_contrib_mask],\n",
    "            orient='h', order=top_feat_interactions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's make another double heatmap plot to observe some of the joint contributions for each prediction in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_contrib_heatmap_df = (joint_contrib_df[top_contrib_mask]\n",
    "                               .groupby(['Player','feat_interaction'])\n",
    "                               .contribution\n",
    "                               .aggregate('first')\n",
    "                               .unstack())\n",
    "joint_contrib_heatmap_df = joint_contrib_heatmap_df.fillna(0)\n",
    "\n",
    "joint_contrib_heatmap_df = joint_contrib_heatmap_df.merge(y_test_and_pred_df, \n",
    "                                                          how='left',\n",
    "                                                          right_index=True, \n",
    "                                                          left_index=True)\n",
    "# sort by predictions\n",
    "joint_contrib_heatmap_df.sort_values('pred_AV_pctile', ascending=True, \n",
    "                                     inplace=True)\n",
    "\n",
    "title = 'Top 15 Joint Feature Contributions to predicted AV %ile\\n(testing data)'\n",
    "fig = double_heatmap(joint_contrib_heatmap_df[['true_AV_pctile', 'pred_AV_pctile']].T,\n",
    "                     joint_contrib_heatmap_df[top_feat_interactions].T, \n",
    "                     cbar_label1='%ile', cbar_label2='contribution', \n",
    "                     title=title, grid_height_ratios=[1, 7], figsize=(14, 12),\n",
    "                     subplot_top=0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDP and ICE plots\n",
    "\n",
    "Individual Conditional Expectation (ICE) plots allow us to visualize how changes for a given feature impact the predictions for a set of observations.\n",
    "\n",
    "Let's use `pycebox` to create an ICE plot to view how changes in the forty yards dash impact our prediction in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycebox.ice import ice, ice_plot\n",
    "\n",
    "# pcyebox likes the data to be in a DataFrame so let's create one with our imputed data\n",
    "# we first need to impute the missing data\n",
    "train_X_imp_df = pd.DataFrame(train_X_imp, columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the ICE values for our feature of interest (Forty) using the `ice` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forty_ice_df = ice(data=train_X_imp_df, column='Forty', \n",
    "                   predict=search.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we create the ICE plot with the `ice_plot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_plot(forty_ice_df, c='dimgray', linewidth=0.3)\n",
    "plt.ylabel('Pred. AV %ile')\n",
    "plt.xlabel('Forty');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how was the above plot created and what is it telling us? To create an ICE plot, we first pick a feature of interest. Then for each observation we make predictions across a range of values for that feature, while holding all other features constant. Finally we just visualize those predictions as curves on a plot. By plotting these curves we are able to observe the relationship between the feature of interest and the predicted target variable. \n",
    "\n",
    "In our ICE plot above we can see how each player's predicted AV percentile tends to decrease in a non-linear manner between forty times of 4.6 seconds and 5.0 seconds.  We can also see that each player's prediction is impacted in a different manner.  For example, it looks like the player predictions at the top of the plot do not decrease as much as those at the bottom. The differences we see among the curves indicate that there are interactions between the forty times and the other features. \n",
    "\n",
    "To inspect feature interactions we can color the ICE curves by another feature.  We can do that by passing in a feature to `ice_plot`'s `color_by` parameter. Let's color each line by the player's weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new colormap for ICE plot\n",
    "cmap2 = plt.get_cmap('OrRd')\n",
    "# set color_by to Wt, in order to color each curve by that player's weight\n",
    "ice_plot(forty_ice_df, linewidth=0.5, color_by='Wt', cmap=cmap2)\n",
    "# ice_plot doesn't return a colorbar so we have to add one\n",
    "# hack to add in colorbar taken from here:\n",
    "# https://stackoverflow.com/questions/8342549/matplotlib-add-colorbar-to-a-sequence-of-line-plots/11558629#11558629\n",
    "wt_vals = forty_ice_df.columns.get_level_values('Wt').values\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap2, \n",
    "                           norm=plt.Normalize(vmin=wt_vals.min(), \n",
    "                                              vmax=wt_vals.max()))\n",
    "# need to create fake array for the scalar mappable or else we get an error\n",
    "sm._A = []\n",
    "plt.colorbar(sm, label='Wt')\n",
    "plt.ylabel('Pred. AV %ile')\n",
    "plt.xlabel('Forty');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above we can see that heavier players are not impacted in the same manner as lighter ones.\n",
    "\n",
    "We can also add the PDP by setting the `plot_pdp` to `True` in the `ice_plot` function. To adjust the styling of the PDP line we pass a dictionary of settings to `pdp_kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_plot(forty_ice_df, linewidth=.5, color_by='Wt', cmap=cmap2, plot_pdp=True, \n",
    "         pdp_kwargs={'c': 'k', 'linewidth': 5})\n",
    "plt.colorbar(sm, label='Wt')\n",
    "plt.ylabel('Pred. AV %ile')\n",
    "plt.xlabel('Forty');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDP is the average of all ICE curves on the plot, so the PDP above represents the average change in the predicted AV percentile over the range of forty times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centered ICE Plots\n",
    "\n",
    "One drawback with our previous ICE plots is that the stacked nature of the lines can make it difficult to observe the differences between the ICE curves. To make it easier to spot those differences we can center or \"pinch\" the curves at a specific feature value. Typically the minimum is a good centering point. With these centered ICE plots we observe the relative change of the predictions with respect to the predictions at the centered value.\n",
    "\n",
    "To center our ICE curves at the minimum Forty value we just set `centered` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_plot(forty_ice_df, linewidth=.5, color_by='Wt', cmap=cmap2, plot_pdp=True, \n",
    "         pdp_kwargs={'c': 'k', 'linewidth': 5}, centered=True)\n",
    "plt.colorbar(sm, label='Wt')\n",
    "plt.ylabel('Pred. AV %ile (centered)')\n",
    "plt.xlabel('Forty');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each line above starts at 0. The y-axis now represents the difference in each player's prediction relative to their prediction at the minimum forty yard dash time  of 4.47 seconds.\n",
    "\n",
    "Let's take a look at the ICE plots for all our features. To make that easier to do, I created a helper function that can plot out all the ICE plots for each feature. It also adds a rug plot at the bottom of each ICE plot to display information about the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ice_grid(dict_of_ice_dfs, data_df, features, ax_ylabel='', nrows=3, \n",
    "                  ncols=3, figsize=(12, 12), sharex=False, sharey=True, \n",
    "                  subplots_kws={}, rug_kws={'color':'k'}, **ice_plot_kws):\n",
    "    \"\"\"A function that plots ICE plots for different features in a grid.\"\"\"\n",
    "    fig, axes = plt.subplots(nrows=nrows, \n",
    "                             ncols=ncols, \n",
    "                             figsize=figsize,\n",
    "                             sharex=sharex,\n",
    "                             sharey=sharey,\n",
    "                             **subplots_kws)\n",
    "    # for each feature plot the ice curves and add a rug at the bottom of the \n",
    "    # subplot\n",
    "    for f, ax in zip(features, axes.flatten()):\n",
    "        ice_plot(dict_of_ice_dfs[f], ax=ax, **ice_plot_kws)\n",
    "        # add the rug\n",
    "        sns.distplot(data_df[f], ax=ax, hist=False, kde=False, \n",
    "                     rug=True, rug_kws=rug_kws)\n",
    "        ax.set_title('feature = ' + f)\n",
    "        ax.set_ylabel(ax_ylabel)\n",
    "        sns.despine()\n",
    "        \n",
    "    # get rid of blank plots\n",
    "    for i in range(len(features), nrows*ncols):\n",
    "        axes.flatten()[i].axis('off')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of ICE data for grid of ICE plots\n",
    "train_ice_dfs = {feat: ice(data=train_X_imp_df, column=feat, predict=estimator.predict) \n",
    "                 for feat in features}\n",
    "\n",
    "fig = plot_ice_grid(train_ice_dfs, train_X_imp_df, features,\n",
    "                    ax_ylabel='Pred. AV %ile', alpha=0.3, plot_pdp=True,\n",
    "                    pdp_kwargs={'c': 'red', 'linewidth': 3},\n",
    "                    linewidth=0.5, c='dimgray')\n",
    "fig.tight_layout()\n",
    "fig.suptitle('ICE plots (training data)')\n",
    "fig.subplots_adjust(top=0.89);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ice_grid(train_ice_dfs, train_X_imp_df, features, \n",
    "                    ax_ylabel='Pred AV %ile (centered)',\n",
    "                    alpha=.2, plot_points=False, plot_pdp=True,\n",
    "                    pdp_kwargs={\"c\": \"red\", \"linewidth\": 3},\n",
    "                    linewidth=0.5, c='dimgray', centered=True,\n",
    "                    sharey=False, nrows=4, ncols=2, figsize=(11,16))\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Centered ICE plots (training data)')\n",
    "fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-dimensional PDPs\n",
    "We can also create plot the PDPs for 2 features at once. This allows us to better understand interactions between the features and how they impact the predictions. We'll use the the `pdpbox` library to create 2-D PDPs.\n",
    "\n",
    "**NOTE** `pdpbox` can also create the same kind of ice plots that we created with `pycebox` above. However `pycebox` doesn't have support for 2-D PDPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pdpbox import pdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm just going to jump into creating a grid of 2-D PDPs and explain whats happening in comments of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.text import Text\n",
    "\n",
    "def plot_2d_pdp_grid(pdp_inters, feature_pairs,\n",
    "                     ncols=3, nrows=4, figsize=(13, 16),\n",
    "                     xaxis_font_size=12, yaxis_font_size=12,\n",
    "                     contour_line_fontsize=12,\n",
    "                     tick_labelsize=10, x_quantile=None, \n",
    "                     plot_params=None, subplots_kws={}):\n",
    "    \"\"\"Plots a grid of 2D PDP plots.\"\"\"\n",
    "    # create our subplots to plot our PDPs on\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, \n",
    "                             figsize=figsize, **subplots_kws)\n",
    "\n",
    "    # for each feature pair, plot the 2-D pdp\n",
    "    for pdp_inter, feat_pair, ax in zip(pdp_inters, feature_pairs, axes.flatten()):\n",
    "    \n",
    "        # use pdpbox's _pdp_contour_plot function to actually plot the 2D pdp\n",
    "        pdp._pdp_contour_plot(pdp_inter, feat_pair, \n",
    "                              x_quantile=x_quantile, ax=ax, \n",
    "                              plot_params=plot_params,\n",
    "                              fig=None)\n",
    "        # adjust some font sizes\n",
    "        ax.tick_params(labelsize=tick_labelsize)\n",
    "        ax.xaxis.get_label().set_fontsize(xaxis_font_size)\n",
    "        ax.yaxis.get_label().set_fontsize(yaxis_font_size)\n",
    "    \n",
    "        # set the contour line fontsize\n",
    "        for child in ax.get_children():\n",
    "            if isinstance(child, Text):\n",
    "                child.set(fontsize=contour_line_fontsize)   \n",
    "    \n",
    "    # get rid of empty subplots\n",
    "    for i in range(len(pdp_inters), nrows*ncols):\n",
    "        axes.flatten()[i].axis('off')\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each possible feature pair combination\n",
    "feature_pairs = [list(feat_pair) for feat_pair in itertools.combinations(features, 2)]\n",
    "# we will only plot the feature iteractions that invlove either Forty or Wt\n",
    "# just to avoid making soooo many plots\n",
    "forty_wt_feat_pairs = [fp for fp in feature_pairs if 'Forty' in fp or 'Wt' in fp]\n",
    "# now calculate the data for the pdp interactions\n",
    "# we can do that with pdpbox's pdp_interact function\n",
    "# in the current development version on github, parallelization is supported\n",
    "# but it didn't work for me so I resorted to using that multiprocess helper\n",
    "# function from before\n",
    "train_feat_inters = multiproc_iter_func(N_JOBS, forty_wt_feat_pairs, \n",
    "                                        pdp.pdp_interact, 'features',\n",
    "                                        model=estimator, train_X=train_X_imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# and now plot a grid of PDP interaction plots\n",
    "# NOTE that the contour colors do not represent the same values\n",
    "# across the different subplots\n",
    "fig = plot_2d_pdp_grid(train_feat_inters, forty_wt_feat_pairs)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('PDP Interaction Plots (training data)', fontsize=20)\n",
    "fig.subplots_adjust(top=0.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME\n",
    "\n",
    "Local interpretable model-agnostic explanations (LIME) allow us to explain individual predictions for \"black box\" models by creating local, interpretable, surrogate models. We fit a local model using the following recipe (which I copied from [Christop Molnar's](https://twitter.com/ChristophMolnar) great book, [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/lime.html)):\n",
    "\n",
    "> \n",
    "- Choose your instance of interest for which you want to have an explanation of its black box prediction.\n",
    "- Perturb your dataset and get the black box predictions for these new points.\n",
    "- Weight the new samples by their proximity to the instance of interest.\n",
    "- Fit a weighted, interpretable model on the dataset with the variations.\n",
    "- Explain prediction by interpreting the local model.\n",
    "\n",
    "There are different packages that implement LIME (including `eli5` and another package I just discovered called `Skater`). Here we will use the original `lime` package created by the authors of the LIME [paper](https://arxiv.org/abs/1602.04938)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our LIME explainer and explain an instance from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the explainer by passing our training data, \n",
    "# setting the correct modeling mode, pass in feature names and\n",
    "# make sure we don't discretize the continuous features\n",
    "explainer = LimeTabularExplainer(train_X_imp_df, mode='regression', \n",
    "                                 feature_names=features, \n",
    "                                 random_state=RANDOM_STATE, \n",
    "                                 discretize_continuous=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_imp_df = pd.DataFrame(test_X_imp, columns=features)\n",
    "# the number of features to include in our predictions\n",
    "num_features = len(features)\n",
    "# the index of the instance we want to explaine\n",
    "exp_idx = 2\n",
    "exp = explainer.explain_instance(test_X_imp_df.iloc[exp_idx,:].values, \n",
    "                                 estimator.predict, num_features=num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now we have our explanation, let's inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction made by the local surrogate model\n",
    "exp.local_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bias term for the local explanation\n",
    "exp.intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a plot of the weights for each feature\n",
    "exp.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and a prettier output that we can view in the notebook\n",
    "# # it looks like it messes with the blog post so I've commented it out\n",
    "# exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have an explanation for that one instance, what about the rest of the test set? We can use the `apply` method to get explanation for the whole test set.\n",
    "\n",
    "**NOTE:** We can't parallelize `explain_instance` with the multiprocessing function since `explain_instance` is a bound method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_expl = test_X_imp_df.apply(explainer.explain_instance, \n",
    "                                predict_fn=estimator.predict, \n",
    "                                num_features=num_features,\n",
    "                                axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on we should double check and see that the local predictions from our surrogate models match our actual predictions. We can judge the local prediction by looking at either the root-mean-squared error or the R<sup>2</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the lime predictions\n",
    "lime_pred = lime_expl.apply(lambda x: x.local_pred[0])\n",
    "# RMSE of lime pred\n",
    "mean_squared_error(y_pred, lime_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2 of lime predictions\n",
    "r2_score(y_pred, lime_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't satisfied with the fit of the local surrogate models you can try to improve them by playing around with the `kernel_width` parameter in `LimeTabularExplainer`. We will try and improve the surrogate models by decreasing the kernel width to make the fits more local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new explainer with smaller kernel_width\n",
    "better_explainer = LimeTabularExplainer(train_X_imp_df, mode='regression', \n",
    "                                        feature_names=features, \n",
    "                                        random_state=RANDOM_STATE, \n",
    "                                        discretize_continuous=False,\n",
    "                                        kernel_width=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_lime_expl = test_X_imp_df.apply(better_explainer.explain_instance, \n",
    "                                       predict_fn=estimator.predict, \n",
    "                                       num_features=num_features,\n",
    "                                       axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the lime predictions\n",
    "better_lime_pred = better_lime_expl.apply(lambda x: x.local_pred[0])\n",
    "# RMSE of lime pred\n",
    "mean_squared_error(y_pred, better_lime_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2 of lime predictions\n",
    "r2_score(y_pred, better_lime_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new local predictions better match our actual predictions. To view all of our explanations at once we can create heatmap in the same manner we did when looking at the feature contributions. To do that we need to create a `DataFrame` with each instance's feature weights and bias term from the LIME explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a DataFrame with all the feature weights and bias terms from LIME\n",
    "# create an individual dataframe for each explanation\n",
    "lime_dfs = [pd.DataFrame(dict(expl.as_list() + [('bias', expl.intercept[0])]), index=[0]) \n",
    "            for expl in better_lime_expl]\n",
    "# then concatenate them into one big DataFrame\n",
    "lime_expl_df = pd.concat(lime_dfs, ignore_index=True)\n",
    "\n",
    "lime_expl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights for each feature we can measure their prediction contributions by multiplying the weights by the actual feature values. But before we do that we need to scale the data in our test set since LIME scales the data inside the explainer when the data is not discretized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaled_X = (test_X_imp_df - explainer.scaler.mean_) / explainer.scaler.scale_\n",
    "# calc the lime feature contributions\n",
    "lime_feat_contrib = lime_expl_df[features] * scaled_X\n",
    "\n",
    "# add on bias term, actual av %ile and predicted %ile\n",
    "other_lime_cols = ['bias', 'true_AV_pctile', 'pred_AV_pctile']\n",
    "lime_feat_contrib[other_lime_cols] = pd.DataFrame(np.column_stack((lime_expl_df.bias,\n",
    "                                                                   y_test_and_pred_df)))\n",
    "\n",
    "lime_feat_contrib.sort_values('pred_AV_pctile', inplace=True)\n",
    "\n",
    "lime_feat_contrib.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to plot each set of explanations using our `double_heatmap` function. Unlike previous heatmaps, we will include the bias terms since the surrogate models that LIME creates can have different bias terms for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title = 'LIME Feature Contributions for each prediction in the testing data'\n",
    "fig = double_heatmap(lime_feat_contrib[['true_AV_pctile', 'pred_AV_pctile']].T,\n",
    "                     lime_feat_contrib.loc[:, :'bias'].T, title=title,\n",
    "                     cbar_label1='%ile', cbar_label2='contribution', \n",
    "                     subplot_top=0.9)\n",
    "# set the x-axis label for the bottom heatmap\n",
    "# fig has 4 axes object, the first 2 are the heatmaps, the other 2 are the colorbars\n",
    "fig.axes[1].set_xlabel('Player');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) is a recent method for model interpretation that leverages game theory to help measure the impact of the features on the predictions. What’s the benefit of using the SHAP method for individual feature contributions over the decision path method from before? Well with the decision path method we have to traverse down the decision tree crediting each feature for the difference in the predictions. This can result in individual contributions that favor features found in splits lower in the tree. The SHAP method doesn't have that problem as it doesn't rely on the order of the features specified by the tree, instead it calculates the contributions by basically averaging the differences in predictions over every possible feature ordering.  For more on this topic I suggest reading Scott Lindburg’s (one of the authors of the SHAP paper) [blog post](https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27).  And for a good explanation of how SHAP values are calculated I suggest reading the [chapter on SHAP](https://christophm.github.io/interpretable-ml-book/shapley.html#) from Christopher Molnar's book.\n",
    "\n",
    "\n",
    "Now let's actually use the SHAP method to explain our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# create our SHAP explainer\n",
    "shap_explainer = shap.TreeExplainer(estimator)\n",
    "# calculate the shapley values for our test set\n",
    "test_shap_vals = shap_explainer.shap_values(test_X_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shap` package provides us with convenience functions to help us plot the SHAP values for our predictions. We can use `force_plot` to inspect individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS in order to use some of the plotting functions from the shap\n",
    "# package in the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the explanation for a single prediction\n",
    "shap.force_plot(test_shap_vals[0, :], test_X_imp_df.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above explanation we can see that there is a base value (i.e. a bias term) of 0.4219, and that each feature pushes (i.e. adds to) that value in order to reach a final prediction of 0.46.\n",
    "  \n",
    "\n",
    "We can also use the `force_plot` function to look at the explanations for our whole dataset. When using the function in a notebook, it produces an interactive plot that allows you to inspect the SHAP values for each observation by hovering the mouse over the plot. By default the observations are clustered together by how similar they are. For example, the first 17 observations in the plot below are players whose weights have a very large positive impact on their predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(test_shap_vals, test_X_imp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the distribution of each feature's SHAP we can use the `summary_plot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(test_shap_vals, test_X_imp_df, auto_size_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `dependence_plot` function we can see how a feature's SHAP values change over the range of feature values. The function automatically colors each point on the plot by a 2nd feature, allowing us to better understand the interaction effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feat in features:\n",
    "    shap.dependence_plot(feat, test_shap_vals, test_X_imp_df, \n",
    "                         dot_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course a heatmap of the SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shap_df = pd.DataFrame(np.column_stack((test_shap_vals, y_test_and_pred_df)),\n",
    "                            columns= features + ['bias', 'true_AV_pctile', \n",
    "                                                 'pred_AV_pctile'])\n",
    "test_shap_df.sort_values('pred_AV_pctile', inplace=True)\n",
    "\n",
    "title = 'SHAP Values for each prediction in the testing data'\n",
    "fig = double_heatmap(test_shap_df[['true_AV_pctile', 'pred_AV_pctile']].T,\n",
    "                     test_shap_df[features].T, '%ile', 'SHAP Value',\n",
    "                     title=title, subplot_top=0.89)\n",
    "fig.axes[1].set_xlabel('Player');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you found this blog post helpful.  If you see any mistakes, have any questions or suggestions  [or if you're hiring :)] you can email me at savvas.tjortjoglou@gmail.com, hit me up on Twitter [@savvastj](https://twitter.com/savvastj), or just leave a comment below.\n",
    "\n",
    "If you like this post and want to support my blog you can check out my patreon page [here](https://www.patreon.com/savvastj).\n",
    "\n",
    "# Resources\n",
    "\n",
    "Here are a list of resources that I found helpful when writing up this post:\n",
    "\n",
    "**General**\n",
    "- [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)\n",
    "\n",
    "**Feature Importance**\n",
    "- [How are feature_importances in RandomForestClassifier determined?](https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined)\n",
    "- [Selecting good features – Part III: random forests](http://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "\n",
    "**Feature Contributions**\n",
    "- [Interpreting random forests](http://blog.datadive.net/interpreting-random-forests/)\n",
    "- [Random forest interpretation with scikit-learn](http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/)\n",
    "- [Random forest interpretation – conditional feature contributions](http://blog.datadive.net/random-forest-interpretation-conditional-feature-contributions/)\n",
    "\n",
    "**ICE plots and PDPs**\n",
    "- [Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation](https://arxiv.org/abs/1309.6392)\n",
    "\n",
    "**LIME**\n",
    "- [\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\n",
    "- [Why your relationship is likely to last (or not): using Local Interpretable Model-Agnostic Explanations (LIME)](http://blog.fastforwardlabs.com/2017/09/01/LIME-for-couples.html)\n",
    "- [Understanding LIME](https://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.html)\n",
    "\n",
    "**SHAP**\n",
    "- [Interpretable Machine Learning with XGBoost](https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27)\n",
    "- [Consistent Individualized Feature Attribution for Tree Ensembles](https://arxiv.org/abs/1802.03888)\n",
    "\n",
    "**NFL Combine/Draft**\n",
    "- The NFL Combine Actually Matters\n",
    "    - [Part 1](http://harvardsportsanalysis.org/2015/02/the-nfl-combine-actually-matters/)\n",
    "    - [Part 2](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-2/)\n",
    "    - [Part 3](http://harvardsportsanalysis.org/2015/02/the-combine-actually-matters-part-3-predicting-the-draft/)\n",
    "\n",
    "    \n",
    "**Videos**\n",
    "- [Machine Learning and Interpretability](https://www.youtube.com/watch?v=NxYCY8-Qfx0)\n",
    "- [Towards interpretable reliable models](https://www.youtube.com/watch?v=B3PtcF-6Dtc)\n",
    "- [Interpretable Machine Learning Using LIME Framework](https://www.youtube.com/watch?v=CY3t11vuuOM)\n",
    "- [Explaining behavior of Machine Learning models with eli5 library](https://www.youtube.com/watch?v=s-yT5Is1G1A)\n",
    "\n",
    "**Model Interpretability Packages**\n",
    "- [treeinterpreter](https://github.com/andosa/treeinterpreter)\n",
    "- [eli5](https://github.com/TeamHG-Memex/eli5/tree/master/eli5)\n",
    "- [pycebox](https://github.com/AustinRochford/PyCEbox)\n",
    "- [pdpbox](https://github.com/SauceCat/PDPbox)\n",
    "- [lime](https://github.com/marcotcr/lime)\n",
    "- [shap](https://github.com/slundberg/shap)\n",
    "- [Skater](https://github.com/datascienceinc/Skater)\n",
    "    \n",
    "As always you can find the notebook and data used for this post on [github](https://github.com/savvastj/model_interpretability_post)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
